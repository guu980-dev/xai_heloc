{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## 데이터 가져오기\n","## 모델 학습\n","## 모델 평가\n","## SHAP 해석\n","## LIME 해석"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# shap 설치\n","!pip install shap"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# lime 설치\n","!pip install lime"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 패키지 가져오기\n","import pandas as pd\n","import numpy as np\n","import shap\n","import lime\n","import sklearn\n","import shap\n","shap.initjs() # load JS visualization code to notebook\n","import xgboost\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,roc_auc_score\n","import matplotlib.pyplot as plt\n","plt.rcParams['figure.facecolor'] = 'white'\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 데이터 가져오기 및 X와 y 구분\n","heloc = pd.read_csv('data/heloc_dataset_v1 (1).csv')\n","X = heloc.drop(columns = 'RiskPerformance')\n","y = heloc.RiskPerformance.replace(to_replace=['Bad', 'Good'], value=[1, 0])"]},{"cell_type":"code","execution_count":89,"metadata":{"trusted":true},"outputs":[],"source":["# 훈련 세트 및 테스트 세트 분할\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n","X_train_array = np.array(X_train)\n","X_test_array = np.array(X_test)\n","y_train_array = np.array(y_train)\n","y_test_array = np.array(y_test)"]},{"cell_type":"code","execution_count":90,"metadata":{"trusted":true},"outputs":[],"source":["# # 通过超参数搜索构建XGBoost模型\n","# xgb_n_estimators = [int(x) for x in np.linspace(200, 2000, 10)] # Number of trees to be used\n","# xgb_max_depth = [int(x) for x in np.linspace(2, 20, 10)] # Maximum number of levels in tree\n","# xgb_min_child_weight = [int(x) for x in np.linspace(1, 10, 10)] # Minimum number of instaces needed in each node\n","# xgb_tree_method = ['auto', 'exact', 'approx', 'hist', 'gpu_hist'] # Tree construction algorithm used in XGBoost\n","# xgb_eta = [x for x in np.linspace(0.1, 0.6, 6)] # Learning rate\n","# xgb_gamma = [int(x) for x in np.linspace(0, 0.5, 6)] # Minimum loss reduction required to make further partition\n","# # # Learning objective used\n","# # xgb_objective = ['binary:logistic', 'binary:hinge']\n","# # Create the grid\n","# xgb_grid = {'n_estimators': xgb_n_estimators,\n","#             'max_depth': xgb_max_depth,\n","#             'min_child_weight': xgb_min_child_weight,\n","#             'tree_method': xgb_tree_method,\n","#             'eta': xgb_eta,\n","#             'gamma': xgb_gamma}\n","# # Create the model to be tuned\n","# xgb_base = xgboost.XGBClassifier()\n","# # Create the random search \n","# xgb_random = RandomizedSearchCV(estimator = xgb_base, param_distributions = xgb_grid, \n","#                                 n_iter = 5, cv = 3, verbose = 2, \n","#                                 random_state = 42, n_jobs = -1)\n","# # Fit the random search model\n","# xgb_random.fit(X_train_array, y_train_array)\n","# # Get the optimal parameters\n","# xgb_random.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 최종 XGBoost 모델 훈련\n","xgb_final = xgboost.XGBClassifier(tree_method = 'hist',\n","                         n_estimators = 800,\n","                         min_child_weight = 6,\n","                         max_depth = 2,\n","                         gamma = 0,\n","                         eta = 0.4,\n","                         early_stop=10,\n","                         random_state = 42)\n","xgb_final.fit(X_train_array, y_train_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 모델 평가\n","def model_eval(model, title, test_features, test_labels):\n","    scores = pd.DataFrame()\n","    predictions = model.predict(test_features)\n","    accuracy = accuracy_score(test_labels,predictions)\n","    roc_auc = roc_auc_score(test_labels,predictions)\n","    F1 = f1_score(test_labels,predictions)\n","    precision = precision_score(test_labels,predictions)\n","    recall = recall_score(test_labels,predictions)\n","    scores[title] = [accuracy,roc_auc,F1,precision,recall]\n","    scores.index = ['Accuracy Score', 'ROC_AUC', 'F1_Score', 'Precision_Score','Recall_Score']\n","    return scores\n","train_scores = model_eval(xgb_final,\"train\",X_train_array,y_train_array)\n","test_scores = model_eval(xgb_final, \"test\",X_test_array, y_test_array)\n","print(train_scores)\n","print(test_scores)"]},{"cell_type":"code","execution_count":93,"metadata":{"trusted":true},"outputs":[],"source":["# XGBOOST 모델 기반 해석기 구축\n","explainer = shap.TreeExplainer(xgb_final)\n","shap_values = explainer.shap_values(X)\n","shap_interaction_values = explainer.shap_interaction_values(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 첫 번째 샘플의 국부 결과 귀인을 추진력 그래프로 표시 (local?)\n","shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:], matplotlib=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["first_result = xgb_final.predict(X.iloc[0:1,:])\n","print(first_result)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 여러 샘플의 전역 결과 귀인을 힘 그래프로 표시 (global?)\n","shap.force_plot(explainer.expected_value, shap_values[:100,:], X.iloc[:100,:])"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 전역 결과 귀인을 막대 그래프로 표시\n","shap.summary_plot(shap_values, X, plot_type=\"bar\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["shap.summary_plot(shap_interaction_values,X)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 총괄도(산점도)를 통해 전역 결과 귀인을 표시\n","shap.summary_plot(shap_values, X)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 단일 특성의 결과 귀인을 의존성 산점도로 표시\n","shap.dependence_plot(\"ExternalRiskEstimate\", shap_values, X)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 단일 샘플의 결과 귀인을 결정 경로도로 표시\n","shap.decision_plot(explainer.expected_value, shap_values[:1],X.iloc[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 단일 샘플의 결과 귀인을 결정 경로도로 표시 (특성 간 상호작용 포함)간 상호작용 포함) 경로도로 표시 (특성 간 상호작용 포함)\n","shap.decision_plot(explainer.expected_value,shap_interaction_values[:1],X.iloc[1],feature_display_range=slice(None, -20, -1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["shap_explianer_values = explainer(X)\n","shap.plots.beeswarm(shap_explianer_values)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_test.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:], matplotlib=True)\n","\n","# 첫 번쨰 값에 대한 SHAP 값 계산\n","shap_values = explainer.shap_values(X.iloc[0:1])\n","\n","# SHAP 값 DataFrame으로 변환\n","shap_df = pd.DataFrame(shap_values, columns=X.columns)\n","\n","# 결과 출력\n","print(shap_df)"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["# 결과를 CSV 파일로 저장\n","shap_df.to_csv(f'result/shap_values_first_test_data_{0}.csv', index=False)"]},{"cell_type":"code","execution_count":106,"metadata":{"trusted":true},"outputs":[],"source":["feature_names=['ExternalRiskEstimate', 'MSinceOldestTradeOpen',\n","       'MSinceMostRecentTradeOpen', 'AverageMInFile', 'NumSatisfactoryTrades',\n","       'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec',\n","       'PercentTradesNeverDelq', 'MSinceMostRecentDelq',\n","       'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumTotalTrades',\n","       'NumTradesOpeninLast12M', 'PercentInstallTrades',\n","       'MSinceMostRecentInqexcl7days', 'NumInqLast6M', 'NumInqLast6Mexcl7days',\n","       'NetFractionRevolvingBurden', 'NetFractionInstallBurden',\n","       'NumRevolvingTradesWBalance', 'NumInstallTradesWBalance',\n","       'NumBank2NatlTradesWHighUtilization', 'PercentTradesWBalance']\n","#feature_names = X_test.columns.tolist()\n","target_names=['Good','Bad']"]},{"cell_type":"code","execution_count":107,"metadata":{"trusted":true},"outputs":[],"source":["# XGBOOST 모델 기반 LIME 해석기 구축\n","lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names, class_names=target_names, discretize_continuous=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["i = np.random.randint(0, X_test.shape[0])\n","i"]},{"cell_type":"code","execution_count":109,"metadata":{"trusted":true},"outputs":[],"source":["# LIME 해석기를 사용하여 단일 샘플 결과 해석\n","exp = lime_explainer.explain_instance(X_test.iloc[i], xgb_final.predict_proba, num_features=23)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# 결과 귀인 표시 \n","exp.show_in_notebook(show_table=True, show_all=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 기여도를 텍스트로 추출 (i번째 test data에 대해?)\n","feature_effects = exp.as_list()\n","print(\"Feature contributions:\")\n","for feature, effect in feature_effects:\n","    print(f\"{feature}: {effect}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 결과를 데이터프레임으로 변환\n","contrib_df = pd.DataFrame(feature_effects, columns=['Feature', 'Effect'])\n","print(contrib_df)"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[],"source":["# 필요시 CSV 파일로 저장\n","contrib_df.to_csv(f'result/lime_feature_contributions_{i}.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LIME 해석기를 사용하여 단일 샘플 결과 해석\n","exp = lime_explainer.explain_instance(X_test.iloc[0], xgb_final.predict_proba, num_features=23)\n","# 기여도를 텍스트로 추출 (i번째 test data에 대해?)\n","feature_effects = exp.as_list()\n","print(\"Feature contributions:\")\n","for feature, effect in feature_effects:\n","    print(f\"{feature}: {effect}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 결과를 데이터프레임으로 변환\n","contrib_df = pd.DataFrame(feature_effects, columns=['Feature', 'Effect'])\n","print(contrib_df)\n","# 필요시 CSV 파일로 저장\n","contrib_df.to_csv(f'result/lime_feature_contributions_{0}.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
